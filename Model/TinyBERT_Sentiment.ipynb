{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30a4ace-de0d-45d3-9c46-2efb414127e7",
   "metadata": {},
   "source": [
    "# Task - To train a sentiment analysis model for multiclass sentimennt covering total of 8 classes on a given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11093b63-661a-4f04-9f9f-651e2ad32fa1",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e309b1b-77aa-4dc5-b698-b809a27c8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357f84e-d12f-4f63-81a1-cd8a5d845c22",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55d9534-7ac4-4605-8523-0b73152867b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('topical_chat_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44538dd7-c774-4024-b275-b6005c13bff2",
   "metadata": {},
   "source": [
    "# Encoding labels (sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee203ede-d16b-4625-b80e-f3d644982e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938db5d5-dceb-4a5d-bc78-8cdf447efd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b013618-d755-4367-be94-b8d96291ed85",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2deb75fe-296b-45e8-8f87-4a6d8c233428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['message'].tolist(), df['label'].tolist(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b6ae9-e16a-4768-8816-0bc1edbf24a7",
   "metadata": {},
   "source": [
    "# Loading tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ddb59e-8beb-4b82-ab66-c43c8233e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "model = BertForSequenceClassification.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', num_labels=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809531d-846d-4ac6-bb9d-e8532a6787db",
   "metadata": {},
   "source": [
    "# Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a2c65c-ef95-47f7-8688-b79b22648577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6ce8b4-f1b8-472b-b0de-aed53a8c44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset class\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdaeeb1f-c344-408d-a6bd-3793ec1f65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset objects\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce772e-9340-46ef-ae0b-9bf5c8b639a0",
   "metadata": {},
   "source": [
    "# Creating training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d7c4db-811b-41e9-89e5-ccdf765ab52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54360947-f3e2-46b6-aabc-6cd448aa83a8",
   "metadata": {},
   "source": [
    "# Initialising trainer object to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a314d170-c9cb-4612-a186-9440aa49a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3c2fb-25fb-4e33-998c-80b3d9f8968c",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814fd874-fd87-4870-90a7-89876a811e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28257' max='28257' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28257/28257 15:54:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.176500</td>\n",
       "      <td>1.151577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.098500</td>\n",
       "      <td>1.133184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.036100</td>\n",
       "      <td>1.134087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=28257, training_loss=1.1352633810956274, metrics={'train_runtime': 57245.6917, 'train_samples_per_second': 7.898, 'train_steps_per_second': 0.494, 'total_flos': 1621338631004160.0, 'train_loss': 1.1352633810956274, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a08cf-4780-4eec-9f69-6b708624a755",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a53b48-d5fc-46e9-b11b-0cd3f5350ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2355' max='2355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2355/2355 32:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation complete. Model saved.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./sentiment_model')\n",
    "tokenizer.save_pretrained('./sentiment_model')\n",
    "\n",
    "print(\"Training and evaluation complete. Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b52e8-974b-4907-a535-b82849864afc",
   "metadata": {},
   "source": [
    "# Inference function - for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeb13104-85a7-41c5-a6e5-12bea9432e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: I am very happy with your service!\n",
      "Predicted Sentiment: Happy\n",
      "\n",
      "Message: This is the worst experience I have ever had.\n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Message: I feel so curious about the new features.\n",
      "Predicted Sentiment: Curious to dive deeper\n",
      "\n",
      "Message: Lol its funny\n",
      "Predicted Sentiment: Happy\n",
      "\n",
      "Message: This is so bad\n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Message: This is disgusting\n",
      "Predicted Sentiment: Sad\n",
      "\n",
      "Message: A google seqarch takes more energy than sending astronauts to moon!!\n",
      "Predicted Sentiment: Surprised\n",
      "\n",
      "Message: Yeah I heard about his daughter passing away!\n",
      "Predicted Sentiment: Curious to dive deeper\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer for prediction\n",
    "model = BertForSequenceClassification.from_pretrained('./sentiment_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./sentiment_model')\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "    return label_encoder.inverse_transform(predictions.cpu().numpy())[0]\n",
    "\n",
    "# Example predictions\n",
    "new_messages = [\n",
    "    \"I am very happy with your service!\",\n",
    "    \"This is the worst experience I have ever had.\",\n",
    "    \"I feel so curious about the new features.\",\n",
    "    \"Lol its funny\",\n",
    "    \"This is so bad\",\n",
    "    \"This is disgusting\",\n",
    "    \"A google seqarch takes more energy than sending astronauts to moon!!\",\n",
    "    \"Yeah I heard about his daughter passing away!\"\n",
    "]\n",
    "\n",
    "for message in new_messages:\n",
    "    sentiment = predict_sentiment(message)\n",
    "    print(f\"Message: {message}\\nPredicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd264e1-a1a6-46a5-b14f-1099b7003d79",
   "metadata": {},
   "source": [
    "# Loading the accuracy metrics for Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b511142-96c4-4e07-9c74-7aadd26388b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load accuracy metric\n",
    "accuracy_metric = load_metric(\"accuracy\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f03cb01-f897-454c-b1ce-8edcb02fd5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation data to torch tensors\n",
    "val_input_ids = torch.tensor(val_encodings['input_ids'])\n",
    "val_attention_mask = torch.tensor(val_encodings['attention_mask'])\n",
    "val_labels = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a767ada9-8cd7-4508-928d-868283f2dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for validation data\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_mask, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83c81e8a-88a2-484a-bfe9-ebc1b5b2d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_metric.compute(predictions=all_preds, references=all_labels)\n",
    "    return accuracy['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24b9a138-4388-4d85-adb9-37613f97d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5642053296528294\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print accuracy\n",
    "accuracy = calculate_accuracy(model, val_loader)\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5444a30-e1a4-4cd9-ba6d-bd694151c751",
   "metadata": {},
   "source": [
    "# Now calculating accuracy metrics on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c861cdef-6c1d-43ca-a159-423b4b92dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now testing on test data\n",
    "train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(df['message'].tolist(), df['label'].tolist(), test_size=0.2)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "375926c0-289b-481b-bbc8-d62b467fd8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SentimentDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49546c81-9a5d-4dab-afb3-472d68edb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids = torch.tensor(test_encodings['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "393b3fe7-b2b3-4e7b-a826-d3318286aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attention_mask = torch.tensor(test_encodings['attention_mask'])\n",
    "test_labels = torch.tensor(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc365fae-c8db-43e3-b7fe-77b66125731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for test data\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5672e7a7-ec4b-4d99-a542-be8e5d85211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy on test data\n",
    "def calculate_accuracy_test(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_metric.compute(predictions=all_preds, references=all_labels)\n",
    "    return accuracy['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9a84f-6d83-449e-82b3-d6bb6c1b9b6f",
   "metadata": {},
   "source": [
    "# Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc688531-7f13-4828-ae8b-53679982850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6079467034717061\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print test accuracy\n",
    "test_accuracy = calculate_accuracy_test(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cd4744d-c9b1-42f9-86bc-f3601cb6d5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a57aa0f2974473e88bb9fbdc95d56c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37195ab5cd0849e4b057d146e3e7f7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786d75bccd954610858a1cf77efabbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_metric = load_metric(\"precision\", trust_remote_code=True)\n",
    "recall_metric = load_metric(\"recall\", trust_remote_code=True)\n",
    "f1_metric = load_metric(\"f1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3120c18-f2ee-4713-af23-1ccccbfb536b",
   "metadata": {},
   "source": [
    "# Function for calculating different accuracy metrics on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e304d20-f1b0-4a10-b763-3c0681b7ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=all_preds, references=all_labels)\n",
    "    precision = precision_metric.compute(predictions=all_preds, references=all_labels, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=all_preds, references=all_labels, average='weighted')\n",
    "    f1 = f1_metric.compute(predictions=all_preds, references=all_labels, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall'],\n",
    "        'f1': f1['f1']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf05bed1-c8c0-4502-8424-5c766cef9e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6079467034717061\n",
      "Test Precision: 0.5932582433720968\n",
      "Test Recall: 0.6079467034717061\n",
      "Test F1 Score: 0.5964401990449176\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print test metrics\n",
    "test_metrics = calculate_metrics(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_metrics['accuracy']}\")\n",
    "print(f\"Test Precision: {test_metrics['precision']}\")\n",
    "print(f\"Test Recall: {test_metrics['recall']}\")\n",
    "print(f\"Test F1 Score: {test_metrics['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b280bdd-a67e-43fe-8401-2b64e647c653",
   "metadata": {},
   "source": [
    "# Saving label encoder for Inferencing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f32b3221-9cb6-4b5a-9cbe-edf9f5c547f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming `df` is your dataframe\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['sentiment'])\n",
    "\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cece50-9e77-42f6-9741-063381ff8963",
   "metadata": {},
   "source": [
    "# Summary\n",
    "# Model is trained for 16 hours straight  and has a val accuracy of 56%\n",
    "# Accuracy on test data -> 60.79%\n",
    "# Precision -> 59.32%\n",
    "# Recall -> 0.60\n",
    "# F1 score-> 0.59\n",
    "\n",
    "# I have used TinyBERT model for this problem statement becuase it is lighweight while maintaining a significant accuracy level. I have limited computational hardware that's the main reason I went for TinyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1d6b4-b219-44e1-b910-4fd7ccc6054f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
